{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\dicom\\__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import skimage.measure\n",
    "import datagenerators\n",
    "from keras.optimizers import Adam\n",
    "import losses\n",
    "import tensorflow as tf\n",
    "import Network_Building\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','Reg_Data')\n",
    "model_dir = os.path.join('..','models')\n",
    "gpu_id='0'\n",
    "steps_per_epoch = 30\n",
    "batch_size = 1\n",
    "data_loss = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the atlas file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_file='../reg_data/Atlas_Data.npy'\n",
    "atlas_vol = np.load(atlas_file) #['vol'][np.newaxis, ..., np.newaxis]\n",
    "z_max = 64\n",
    "# atlas_vol = atlas_vol[:,:,factor:-factor,factor:-factor,:]\n",
    "atlas_vol = skimage.measure.block_reduce(atlas_vol,(1, 2, 2, 2, 1), np.average)\n",
    "if atlas_vol.shape[1] > z_max:\n",
    "    atlas_vol = atlas_vol[:, -z_max:, ...]\n",
    "holder = (1,z_max,256,256,1) - np.asarray(atlas_vol.shape)\n",
    "val_differences = [[i,0] for i in holder]\n",
    "atlas_vol = np.pad(atlas_vol, val_differences, 'constant', constant_values=(-1000))\n",
    "vol_size = atlas_vol.shape[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your model\n",
    "\n",
    "This is the part that you have the most unique control over, what exactly will your model look like?\n",
    "\n",
    "One good way of visualizing the model is to create it and look at the graphical architecture with tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start off with something simple, a UNet with one concatentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {'Layer_0':{'Encoding':[16,32],'Decoding':[32,16,8]},\n",
    "          'Base':{'Encoding':[64]}}\n",
    "model_desc = 'Shallow_net' # Name of your model\n",
    "# The numbers inside are the number of filter banks, you can have mulitple filter banks per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be imagined as a U net, the numbers within [] are the number of filters in the convolution blocks, the network will first perform convolutions downthe encoding side to the base, and then concatenate from the previous encoding layer before performing decoding convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not look like much, but lets see what it looks like graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\bmanderson\\appdata\\roaming\\python\\python36\\site-packages (2.0.0a0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.0.6)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.2 in c:\\users\\bmanderson\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (0.1.5)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in c:\\users\\bmanderson\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.14.0a20190301)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in c:\\users\\bmanderson\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.14.0.dev2019030115)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.18.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow) (0.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\\Morfeus\\AAPM_SummerSchool\\voxelmorph\\Tensorboard_models\\Shallow_net\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model_class = Network_Building.new_model(image_size=vol_size,layers=layers, visualize=True)\n",
    "model = model_class.model\n",
    "tensorboard_output = os.path.join('..','Tensorboard_models',model_desc)\n",
    "if not os.path.exists(tensorboard_output):\n",
    "    os.makedirs(tensorboard_output)\n",
    "print(os.path.abspath(tensorboard_output))\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_output, batch_size=2, write_graph=True, write_grads=False,\n",
    "                          write_images=True, update_freq='epoch', histogram_freq=0)\n",
    "tensorboard.set_model(model)\n",
    "tensorboard._write_logs({},0)\n",
    "model_output = os.path.join(model_dir, model_desc, 'Model_saves')\n",
    "save_file_name = os.path.join(model_output,'weights-improvement-{epoch:02d}.hdf5')\n",
    "checkpoint = ModelCheckpoint(save_file_name, save_weights_only=False, period=1)\n",
    "callbacks = [checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model\n",
    "Now go to the terminal location printed out above and type\n",
    "\n",
    "tensorboard --logdir=. --host=localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vol_names = glob.glob(os.path.join(data_dir, '*Registered_Data.npy'))\n",
    "train_example_gen = datagenerators.example_gen(train_vol_names, batch_size=batch_size)\n",
    "atlas_vol_bs = np.repeat(atlas_vol, batch_size, axis=0)\n",
    "data_gen = datagenerators.cvpr2018_gen(train_example_gen, atlas_vol_bs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters\n",
    "These are variables which you will manipulate in order to create the best model possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # Rate at which our gradients will change during each back propogation, typically in range of 1e-2 to 1e-5\n",
    "number_of_epochs = 10 # The number of epochs to be trained, one epoch means that you have seen the entirety of your dataset\n",
    "                      # However, since we defined steps per epoch this might not apply\n",
    "regularization_parameter = 0.01 # Lambda in regularization equation\n",
    "steps_per_epoch = 30\n",
    "batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/30 [>.............................] - ETA: 12:47 - loss: 143269.8281 - spatial_transformer_1_loss: 143269.8281 - flow_loss: 1.2845e-08"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "with K.tf.device('/cpu:0'):\n",
    "    model_class = Network_Building.new_model(image_size=vol_size, layers=layers, batch_normalization=batch_normalization)\n",
    "    model = model_class.model\n",
    "    model.compile(optimizer=Adam(lr=learning_rate),\n",
    "                     loss=[data_loss, losses.Grad('l2').loss],\n",
    "                     loss_weights=[1.0, regularization_parameter])\n",
    "\n",
    "    # fit\n",
    "    model.fit_generator(data_gen,\n",
    "                           initial_epoch=0,\n",
    "                           epochs=number_of_epochs,\n",
    "                           callbacks=callbacks,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - ETA: 10:40 - loss: 133980.7969 - spatial_transformer_2_loss: 133980.7969 - flow_loss: 9.6098e-0 - ETA: 5:31 - loss: 131502.8125 - spatial_transformer_2_loss: 131502.8125 - flow_loss: 8.2360e-0 - ETA: 3:48 - loss: 134196.9792 - spatial_transformer_2_loss: 134196.9792 - flow_loss: 3.1711e- - ETA: 2:54 - loss: 134063.4531 - spatial_transformer_2_loss: 134063.4531 - flow_loss: 7.6383e- - ETA: 2:22 - loss: 132965.6063 - spatial_transformer_2_loss: 132965.6063 - flow_loss: 0.0016   - ETA: 2:00 - loss: 136901.8620 - spatial_transformer_2_loss: 136901.8620 - flow_loss: 0.00 - ETA: 1:44 - loss: 135979.6864 - spatial_transformer_2_loss: 135979.6864 - flow_loss: 0.00 - ETA: 1:31 - loss: 134575.4990 - spatial_transformer_2_loss: 134575.4990 - flow_loss: 0.00 - ETA: 1:21 - loss: 133456.4201 - spatial_transformer_2_loss: 133456.4201 - flow_loss: 0.00 - ETA: 1:12 - loss: 132405.3617 - spatial_transformer_2_loss: 132405.3617 - flow_loss: 0.01 - ETA: 1:05 - loss: 131742.0916 - spatial_transformer_2_loss: 131742.0916 - flow_loss: 0.01 - ETA: 59s - loss: 131040.2565 - spatial_transformer_2_loss: 131040.2565 - flow_loss: 0.0139 - ETA: 53s - loss: 130285.5625 - spatial_transformer_2_loss: 130285.5625 - flow_loss: 0.015 - ETA: 48s - loss: 129571.9263 - spatial_transformer_2_loss: 129571.9263 - flow_loss: 0.017 - ETA: 44s - loss: 131346.0271 - spatial_transformer_2_loss: 131346.0271 - flow_loss: 0.020 - ETA: 40s - loss: 130748.3447 - spatial_transformer_2_loss: 130748.3447 - flow_loss: 0.022 - ETA: 36s - loss: 130205.9122 - spatial_transformer_2_loss: 130205.9122 - flow_loss: 0.025 - ETA: 32s - loss: 129659.4779 - spatial_transformer_2_loss: 129659.4779 - flow_loss: 0.027 - ETA: 29s - loss: 129067.0259 - spatial_transformer_2_loss: 129067.0259 - flow_loss: 0.030 - ETA: 26s - loss: 128586.8590 - spatial_transformer_2_loss: 128586.8590 - flow_loss: 0.031 - ETA: 23s - loss: 128128.2228 - spatial_transformer_2_loss: 128128.2228 - flow_loss: 0.033 - ETA: 20s - loss: 127644.1953 - spatial_transformer_2_loss: 127644.1953 - flow_loss: 0.034 - ETA: 17s - loss: 127181.1213 - spatial_transformer_2_loss: 127181.1213 - flow_loss: 0.036 - ETA: 14s - loss: 126713.7334 - spatial_transformer_2_loss: 126713.7334 - flow_loss: 0.038 - ETA: 12s - loss: 126321.6500 - spatial_transformer_2_loss: 126321.6500 - flow_loss: 0.040 - ETA: 9s - loss: 125895.2972 - spatial_transformer_2_loss: 125895.2972 - flow_loss: 0.042 - ETA: 7s - loss: 125469.0249 - spatial_transformer_2_loss: 125469.0249 - flow_loss: 0.04 - ETA: 4s - loss: 125122.5050 - spatial_transformer_2_loss: 125122.5050 - flow_loss: 0.04 - ETA: 2s - loss: 124720.4612 - spatial_transformer_2_loss: 124720.4612 - flow_loss: 0.04 - 68s 2s/step - loss: 124394.1779 - spatial_transformer_2_loss: 124394.1779 - flow_loss: 0.0521\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - ETA: 46s - loss: 113805.8359 - spatial_transformer_2_loss: 113805.8359 - flow_loss: 0.127 - ETA: 45s - loss: 117750.8945 - spatial_transformer_2_loss: 117750.8945 - flow_loss: 0.126 - ETA: 43s - loss: 115888.3490 - spatial_transformer_2_loss: 115888.3490 - flow_loss: 0.137 - ETA: 41s - loss: 115446.6699 - spatial_transformer_2_loss: 115446.6699 - flow_loss: 0.136 - ETA: 39s - loss: 113989.2797 - spatial_transformer_2_loss: 113989.2797 - flow_loss: 0.143 - ETA: 38s - loss: 113312.6562 - spatial_transformer_2_loss: 113312.6562 - flow_loss: 0.154 - ETA: 36s - loss: 113055.9565 - spatial_transformer_2_loss: 113055.9565 - flow_loss: 0.155 - ETA: 34s - loss: 112626.6123 - spatial_transformer_2_loss: 112626.6123 - flow_loss: 0.158 - ETA: 33s - loss: 111813.1536 - spatial_transformer_2_loss: 111813.1536 - flow_loss: 0.163 - ETA: 31s - loss: 111415.7133 - spatial_transformer_2_loss: 111415.7133 - flow_loss: 0.163 - ETA: 30s - loss: 111162.6626 - spatial_transformer_2_loss: 111162.6626 - flow_loss: 0.165 - ETA: 28s - loss: 110230.8353 - spatial_transformer_2_loss: 110230.8353 - flow_loss: 0.170 - ETA: 27s - loss: 109721.5403 - spatial_transformer_2_loss: 109721.5403 - flow_loss: 0.177 - ETA: 25s - loss: 109336.2394 - spatial_transformer_2_loss: 109336.2394 - flow_loss: 0.182 - ETA: 23s - loss: 109003.9245 - spatial_transformer_2_loss: 109003.9245 - flow_loss: 0.187 - ETA: 22s - loss: 108614.6484 - spatial_transformer_2_loss: 108614.6484 - flow_loss: 0.194 - ETA: 20s - loss: 108259.5179 - spatial_transformer_2_loss: 108259.5179 - flow_loss: 0.202 - ETA: 19s - loss: 107896.2131 - spatial_transformer_2_loss: 107896.2131 - flow_loss: 0.210 - ETA: 17s - loss: 107121.0263 - spatial_transformer_2_loss: 107121.0263 - flow_loss: 0.219 - ETA: 15s - loss: 106774.6090 - spatial_transformer_2_loss: 106774.6090 - flow_loss: 0.225 - ETA: 14s - loss: 106410.1414 - spatial_transformer_2_loss: 106410.1414 - flow_loss: 0.231 - ETA: 12s - loss: 105743.5728 - spatial_transformer_2_loss: 105743.5724 - flow_loss: 0.240 - ETA: 11s - loss: 105396.2272 - spatial_transformer_2_loss: 105396.2266 - flow_loss: 0.248 - ETA: 9s - loss: 106267.6169 - spatial_transformer_2_loss: 106267.6159 - flow_loss: 0.257 - ETA: 7s - loss: 105951.1022 - spatial_transformer_2_loss: 105951.1009 - flow_loss: 0.26 - ETA: 6s - loss: 105568.1220 - spatial_transformer_2_loss: 105568.1205 - flow_loss: 0.27 - ETA: 4s - loss: 104929.1484 - spatial_transformer_2_loss: 104929.1467 - flow_loss: 0.28 - ETA: 3s - loss: 104599.7818 - spatial_transformer_2_loss: 104599.7799 - flow_loss: 0.29 - ETA: 1s - loss: 103966.0307 - spatial_transformer_2_loss: 103966.0286 - flow_loss: 0.30 - 48s 2s/step - loss: 103590.6516 - spatial_transformer_2_loss: 103590.6492 - flow_loss: 0.3087\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - ETA: 45s - loss: 92588.2109 - spatial_transformer_2_loss: 92588.2031 - flow_loss: 0.624 - ETA: 44s - loss: 88975.2852 - spatial_transformer_2_loss: 88975.2773 - flow_loss: 0.630 - ETA: 42s - loss: 89486.7344 - spatial_transformer_2_loss: 89486.7266 - flow_loss: 0.638 - ETA: 41s - loss: 89259.1289 - spatial_transformer_2_loss: 89259.1211 - flow_loss: 0.644 - ETA: 39s - loss: 87341.2156 - spatial_transformer_2_loss: 87341.2078 - flow_loss: 0.654 - ETA: 37s - loss: 87485.6836 - spatial_transformer_2_loss: 87485.6758 - flow_loss: 0.676 - ETA: 36s - loss: 85841.6819 - spatial_transformer_2_loss: 85841.6741 - flow_loss: 0.690 - ETA: 34s - loss: 86056.5215 - spatial_transformer_2_loss: 86056.5137 - flow_loss: 0.703 - ETA: 33s - loss: 85935.0243 - spatial_transformer_2_loss: 85935.0165 - flow_loss: 0.710 - ETA: 31s - loss: 85666.8984 - spatial_transformer_2_loss: 85666.8906 - flow_loss: 0.716 - ETA: 30s - loss: 85366.3239 - spatial_transformer_2_loss: 85366.3161 - flow_loss: 0.723 - ETA: 28s - loss: 85175.0651 - spatial_transformer_2_loss: 85175.0573 - flow_loss: 0.733 - ETA: 26s - loss: 84883.8299 - spatial_transformer_2_loss: 84883.8221 - flow_loss: 0.748 - ETA: 25s - loss: 83839.0547 - spatial_transformer_2_loss: 83839.0469 - flow_loss: 0.767 - ETA: 23s - loss: 83766.7714 - spatial_transformer_2_loss: 83766.7635 - flow_loss: 0.788 - ETA: 22s - loss: 83826.1523 - spatial_transformer_2_loss: 83826.1440 - flow_loss: 0.821 - ETA: 20s - loss: 83025.7344 - spatial_transformer_2_loss: 83025.7256 - flow_loss: 0.846 - ETA: 19s - loss: 82810.1719 - spatial_transformer_2_loss: 82810.1628 - flow_loss: 0.866 - ETA: 17s - loss: 82264.0543 - spatial_transformer_2_loss: 82264.0448 - flow_loss: 0.886 - ETA: 15s - loss: 81756.3734 - spatial_transformer_2_loss: 81756.3637 - flow_loss: 0.907 - ETA: 14s - loss: 81469.1674 - spatial_transformer_2_loss: 81469.1574 - flow_loss: 0.931 - ETA: 12s - loss: 81348.2287 - spatial_transformer_2_loss: 81348.2184 - flow_loss: 0.960 - ETA: 11s - loss: 81127.1461 - spatial_transformer_2_loss: 81127.1355 - flow_loss: 0.986 - ETA: 9s - loss: 80813.6820 - spatial_transformer_2_loss: 80813.6712 - flow_loss: 1.009 - ETA: 7s - loss: 80511.7606 - spatial_transformer_2_loss: 80511.7497 - flow_loss: 1.03 - ETA: 6s - loss: 80191.5027 - spatial_transformer_2_loss: 80191.4916 - flow_loss: 1.05 - ETA: 4s - loss: 79783.5220 - spatial_transformer_2_loss: 79783.5107 - flow_loss: 1.08 - ETA: 3s - loss: 79409.2972 - spatial_transformer_2_loss: 79409.2857 - flow_loss: 1.10 - ETA: 1s - loss: 78983.5595 - spatial_transformer_2_loss: 78983.5480 - flow_loss: 1.13 - 47s 2s/step - loss: 78696.3656 - spatial_transformer_2_loss: 78696.3536 - flow_loss: 1.1624\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - ETA: 45s - loss: 68811.8906 - spatial_transformer_2_loss: 68811.8672 - flow_loss: 1.964 - ETA: 44s - loss: 67439.9570 - spatial_transformer_2_loss: 67439.9375 - flow_loss: 1.950 - ETA: 42s - loss: 66664.1706 - spatial_transformer_2_loss: 66664.1510 - flow_loss: 1.985 - ETA: 40s - loss: 64420.0020 - spatial_transformer_2_loss: 64419.9824 - flow_loss: 2.024 - ETA: 39s - loss: 64271.9078 - spatial_transformer_2_loss: 64271.8875 - flow_loss: 2.087 - ETA: 37s - loss: 62901.7852 - spatial_transformer_2_loss: 62901.7643 - flow_loss: 2.133 - ETA: 36s - loss: 61934.2617 - spatial_transformer_2_loss: 61934.2405 - flow_loss: 2.187 - ETA: 34s - loss: 61969.3979 - spatial_transformer_2_loss: 61969.3760 - flow_loss: 2.253 - ETA: 33s - loss: 62350.0095 - spatial_transformer_2_loss: 62349.9870 - flow_loss: 2.314 - ETA: 31s - loss: 62152.0332 - spatial_transformer_2_loss: 62152.0102 - flow_loss: 2.367 - ETA: 30s - loss: 62215.5621 - spatial_transformer_2_loss: 62215.5384 - flow_loss: 2.425 - ETA: 28s - loss: 61843.8730 - spatial_transformer_2_loss: 61843.8486 - flow_loss: 2.483 - ETA: 26s - loss: 61999.7521 - spatial_transformer_2_loss: 61999.7272 - flow_loss: 2.541 - ETA: 25s - loss: 61477.6710 - spatial_transformer_2_loss: 61477.6456 - flow_loss: 2.592 - ETA: 23s - loss: 61727.1706 - spatial_transformer_2_loss: 61727.1445 - flow_loss: 2.645 - ETA: 22s - loss: 61227.8391 - spatial_transformer_2_loss: 61227.8125 - flow_loss: 2.701 - ETA: 20s - loss: 60947.6252 - spatial_transformer_2_loss: 60947.5981 - flow_loss: 2.757 - ETA: 19s - loss: 60571.4275 - spatial_transformer_2_loss: 60571.4000 - flow_loss: 2.808 - ETA: 17s - loss: 60029.6704 - spatial_transformer_2_loss: 60029.6425 - flow_loss: 2.855 - ETA: 15s - loss: 60015.4902 - spatial_transformer_2_loss: 60015.4617 - flow_loss: 2.903 - ETA: 14s - loss: 59909.1187 - spatial_transformer_2_loss: 59909.0897 - flow_loss: 2.946 - ETA: 12s - loss: 59834.5344 - spatial_transformer_2_loss: 59834.5050 - flow_loss: 2.987 - ETA: 11s - loss: 59739.5440 - spatial_transformer_2_loss: 59739.5139 - flow_loss: 3.037 - ETA: 9s - loss: 59553.2318 - spatial_transformer_2_loss: 59553.2013 - flow_loss: 3.081 - ETA: 7s - loss: 59945.9019 - spatial_transformer_2_loss: 59945.8711 - flow_loss: 3.12 - ETA: 6s - loss: 59886.0565 - spatial_transformer_2_loss: 59886.0252 - flow_loss: 3.17 - ETA: 4s - loss: 59992.0841 - spatial_transformer_2_loss: 59992.0524 - flow_loss: 3.22 - ETA: 3s - loss: 59908.5999 - spatial_transformer_2_loss: 59908.5675 - flow_loss: 3.28 - ETA: 1s - loss: 60017.0150 - spatial_transformer_2_loss: 60016.9818 - flow_loss: 3.35 - 48s 2s/step - loss: 59828.9266 - spatial_transformer_2_loss: 59828.8928 - flow_loss: 3.4162\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - ETA: 46s - loss: 56891.5156 - spatial_transformer_2_loss: 56891.4688 - flow_loss: 4.790 - ETA: 44s - loss: 55444.3516 - spatial_transformer_2_loss: 55444.3047 - flow_loss: 4.760 - ETA: 43s - loss: 56907.7357 - spatial_transformer_2_loss: 56907.6875 - flow_loss: 4.803 - ETA: 41s - loss: 54330.9795 - spatial_transformer_2_loss: 54330.9307 - flow_loss: 4.834 - ETA: 40s - loss: 55214.4406 - spatial_transformer_2_loss: 55214.3914 - flow_loss: 4.894 - ETA: 38s - loss: 55036.7207 - spatial_transformer_2_loss: 55036.6712 - flow_loss: 4.921 - ETA: 36s - loss: 54696.6791 - spatial_transformer_2_loss: 54696.6300 - flow_loss: 4.912 - ETA: 35s - loss: 53913.5405 - spatial_transformer_2_loss: 53913.4917 - flow_loss: 4.898 - ETA: 33s - loss: 53835.8550 - spatial_transformer_2_loss: 53835.8064 - flow_loss: 4.887 - ETA: 31s - loss: 53398.5340 - spatial_transformer_2_loss: 53398.4855 - flow_loss: 4.874 - ETA: 30s - loss: 53143.3881 - spatial_transformer_2_loss: 53143.3395 - flow_loss: 4.881 - ETA: 28s - loss: 53099.6608 - spatial_transformer_2_loss: 53099.6120 - flow_loss: 4.895 - ETA: 27s - loss: 53268.2227 - spatial_transformer_2_loss: 53268.1737 - flow_loss: 4.909 - ETA: 25s - loss: 53034.7994 - spatial_transformer_2_loss: 53034.7503 - flow_loss: 4.923 - ETA: 24s - loss: 53181.9198 - spatial_transformer_2_loss: 53181.8706 - flow_loss: 4.942 - ETA: 22s - loss: 52849.0764 - spatial_transformer_2_loss: 52849.0271 - flow_loss: 4.960 - ETA: 20s - loss: 52724.6369 - spatial_transformer_2_loss: 52724.5873 - flow_loss: 4.982 - ETA: 19s - loss: 52386.5933 - spatial_transformer_2_loss: 52386.5434 - flow_loss: 5.009 - ETA: 17s - loss: 51624.8242 - spatial_transformer_2_loss: 51624.7738 - flow_loss: 5.046 - ETA: 16s - loss: 51394.5025 - spatial_transformer_2_loss: 51394.4518 - flow_loss: 5.089 - ETA: 14s - loss: 50742.1036 - spatial_transformer_2_loss: 50742.0523 - flow_loss: 5.140 - ETA: 12s - loss: 50472.6987 - spatial_transformer_2_loss: 50472.6468 - flow_loss: 5.197 - ETA: 11s - loss: 50249.4762 - spatial_transformer_2_loss: 50249.4237 - flow_loss: 5.260 - ETA: 9s - loss: 50105.4121 - spatial_transformer_2_loss: 50105.3590 - flow_loss: 5.320 - ETA: 8s - loss: 49973.4591 - spatial_transformer_2_loss: 49973.4056 - flow_loss: 5.36 - ETA: 6s - loss: 49702.4130 - spatial_transformer_2_loss: 49702.3589 - flow_loss: 5.42 - ETA: 4s - loss: 49542.4368 - spatial_transformer_2_loss: 49542.3819 - flow_loss: 5.49 - ETA: 3s - loss: 49378.2884 - spatial_transformer_2_loss: 49378.2327 - flow_loss: 5.57 - ETA: 1s - loss: 48816.4550 - spatial_transformer_2_loss: 48816.3986 - flow_loss: 5.64 - 48s 2s/step - loss: 48233.6054 - spatial_transformer_2_loss: 48233.5483 - flow_loss: 5.7065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "30/30 [==============================] - ETA: 46s - loss: 31754.5469 - spatial_transformer_2_loss: 31754.4688 - flow_loss: 7.906 - ETA: 45s - loss: 37667.7637 - spatial_transformer_2_loss: 37667.6836 - flow_loss: 8.083 - ETA: 43s - loss: 38709.8242 - spatial_transformer_2_loss: 38709.7409 - flow_loss: 8.326 - ETA: 41s - loss: 36963.3633 - spatial_transformer_2_loss: 36963.2773 - flow_loss: 8.567 - ETA: 40s - loss: 35990.0094 - spatial_transformer_2_loss: 35989.9207 - flow_loss: 8.838 - ETA: 38s - loss: 35104.2627 - spatial_transformer_2_loss: 35104.1719 - flow_loss: 9.053 - ETA: 36s - loss: 34043.6197 - spatial_transformer_2_loss: 34043.5271 - flow_loss: 9.233 - ETA: 35s - loss: 33256.5364 - spatial_transformer_2_loss: 33256.4426 - flow_loss: 9.359 - ETA: 33s - loss: 33161.9164 - spatial_transformer_2_loss: 33161.8218 - flow_loss: 9.448 - ETA: 32s - loss: 32514.8807 - spatial_transformer_2_loss: 32514.7854 - flow_loss: 9.528 - ETA: 30s - loss: 33312.1454 - spatial_transformer_2_loss: 33312.0492 - flow_loss: 9.624 - ETA: 28s - loss: 33831.4386 - spatial_transformer_2_loss: 33831.3410 - flow_loss: 9.752 - ETA: 27s - loss: 33282.7261 - spatial_transformer_2_loss: 33282.6268 - flow_loss: 9.921 - ETA: 25s - loss: 32898.1161 - spatial_transformer_2_loss: 32898.0151 - flow_loss: 10.09 - ETA: 24s - loss: 33330.7664 - spatial_transformer_2_loss: 33330.6638 - flow_loss: 10.25 - ETA: 22s - loss: 32904.1078 - spatial_transformer_2_loss: 32904.0040 - flow_loss: 10.37 - ETA: 20s - loss: 33374.0199 - spatial_transformer_2_loss: 33373.9158 - flow_loss: 10.41 - ETA: 19s - loss: 33718.2709 - spatial_transformer_2_loss: 33718.1661 - flow_loss: 10.49 - ETA: 17s - loss: 33338.9627 - spatial_transformer_2_loss: 33338.8570 - flow_loss: 10.57 - ETA: 16s - loss: 33581.1345 - spatial_transformer_2_loss: 33581.0278 - flow_loss: 10.66 - ETA: 14s - loss: 33811.0033 - spatial_transformer_2_loss: 33810.8956 - flow_loss: 10.76 - ETA: 12s - loss: 33439.8901 - spatial_transformer_2_loss: 33439.7812 - flow_loss: 10.88 - ETA: 11s - loss: 33444.2948 - spatial_transformer_2_loss: 33444.1845 - flow_loss: 11.02 - ETA: 9s - loss: 33848.3428 - spatial_transformer_2_loss: 33848.2310 - flow_loss: 11.1637 - ETA: 8s - loss: 33495.7652 - spatial_transformer_2_loss: 33495.6523 - flow_loss: 11.277 - ETA: 6s - loss: 33194.8577 - spatial_transformer_2_loss: 33194.7438 - flow_loss: 11.380 - ETA: 4s - loss: 32951.5718 - spatial_transformer_2_loss: 32951.4569 - flow_loss: 11.477 - ETA: 3s - loss: 32678.7608 - spatial_transformer_2_loss: 32678.6449 - flow_loss: 11.576 - ETA: 1s - loss: 32924.5972 - spatial_transformer_2_loss: 32924.4802 - flow_loss: 11.686 - 48s 2s/step - loss: 32655.8816 - spatial_transformer_2_loss: 32655.7635 - flow_loss: 11.8078\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - ETA: 46s - loss: 25217.0215 - spatial_transformer_2_loss: 25216.8633 - flow_loss: 15.88 - ETA: 44s - loss: 24681.4209 - spatial_transformer_2_loss: 24681.2617 - flow_loss: 15.90 - ETA: 43s - loss: 29148.6582 - spatial_transformer_2_loss: 29148.4987 - flow_loss: 15.92 - ETA: 41s - loss: 31293.7417 - spatial_transformer_2_loss: 31293.5820 - flow_loss: 15.95 - ETA: 40s - loss: 32381.5332 - spatial_transformer_2_loss: 32381.3734 - flow_loss: 15.93 - ETA: 38s - loss: 33471.8070 - spatial_transformer_2_loss: 33471.6471 - flow_loss: 15.93 - ETA: 36s - loss: 34030.7263 - spatial_transformer_2_loss: 34030.5670 - flow_loss: 15.89 - ETA: 35s - loss: 34290.5266 - spatial_transformer_2_loss: 34290.3682 - flow_loss: 15.82 - ETA: 33s - loss: 34742.4703 - spatial_transformer_2_loss: 34742.3125 - flow_loss: 15.74 - ETA: 32s - loss: 35089.8330 - spatial_transformer_2_loss: 35089.6762 - flow_loss: 15.66 - ETA: 30s - loss: 35372.2864 - spatial_transformer_2_loss: 35372.1303 - flow_loss: 15.60 - ETA: 28s - loss: 34547.7013 - spatial_transformer_2_loss: 34547.5457 - flow_loss: 15.55 - ETA: 27s - loss: 33831.2360 - spatial_transformer_2_loss: 33831.0805 - flow_loss: 15.55 - ETA: 25s - loss: 33141.4019 - spatial_transformer_2_loss: 33141.2461 - flow_loss: 15.58 - ETA: 24s - loss: 33897.7694 - spatial_transformer_2_loss: 33897.6135 - flow_loss: 15.59 - ETA: 22s - loss: 33909.1730 - spatial_transformer_2_loss: 33909.0166 - flow_loss: 15.64 - ETA: 20s - loss: 34048.9808 - spatial_transformer_2_loss: 34048.8238 - flow_loss: 15.71 - ETA: 19s - loss: 33452.4214 - spatial_transformer_2_loss: 33452.2637 - flow_loss: 15.78 - ETA: 17s - loss: 33447.0907 - spatial_transformer_2_loss: 33446.9319 - flow_loss: 15.86 - ETA: 16s - loss: 33114.8904 - spatial_transformer_2_loss: 33114.7308 - flow_loss: 15.96 - ETA: 14s - loss: 33366.3531 - spatial_transformer_2_loss: 33366.1924 - flow_loss: 16.06 - ETA: 12s - loss: 33493.0574 - spatial_transformer_2_loss: 33492.8962 - flow_loss: 16.11 - ETA: 11s - loss: 33599.4076 - spatial_transformer_2_loss: 33599.2458 - flow_loss: 16.18 - ETA: 9s - loss: 33885.4412 - spatial_transformer_2_loss: 33885.2789 - flow_loss: 16.2473 - ETA: 8s - loss: 33853.8528 - spatial_transformer_2_loss: 33853.6899 - flow_loss: 16.307 - ETA: 6s - loss: 33852.3848 - spatial_transformer_2_loss: 33852.2212 - flow_loss: 16.371 - ETA: 4s - loss: 34250.8519 - spatial_transformer_2_loss: 34250.6882 - flow_loss: 16.392 - ETA: 3s - loss: 33871.5058 - spatial_transformer_2_loss: 33871.3413 - flow_loss: 16.466 - ETA: 1s - loss: 33958.4931 - spatial_transformer_2_loss: 33958.3278 - flow_loss: 16.549 - 48s 2s/step - loss: 33627.3460 - spatial_transformer_2_loss: 33627.1798 - flow_loss: 16.6418\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - ETA: 47s - loss: 23562.4219 - spatial_transformer_2_loss: 23562.2324 - flow_loss: 19.04 - ETA: 45s - loss: 27423.9746 - spatial_transformer_2_loss: 27423.7930 - flow_loss: 18.26 - ETA: 43s - loss: 29650.5586 - spatial_transformer_2_loss: 29650.3750 - flow_loss: 18.43 - ETA: 42s - loss: 30812.2793 - spatial_transformer_2_loss: 30812.0938 - flow_loss: 18.64 - ETA: 40s - loss: 32636.3492 - spatial_transformer_2_loss: 32636.1617 - flow_loss: 18.83 - ETA: 38s - loss: 33304.1452 - spatial_transformer_2_loss: 33303.9557 - flow_loss: 19.00 - ETA: 37s - loss: 33791.9191 - spatial_transformer_2_loss: 33791.7282 - flow_loss: 19.11 - ETA: 35s - loss: 34199.8599 - spatial_transformer_2_loss: 34199.6685 - flow_loss: 19.18 - ETA: 34s - loss: 39984.8016 - spatial_transformer_2_loss: 39984.6107 - flow_loss: 19.09 - ETA: 32s - loss: 40005.4754 - spatial_transformer_2_loss: 40005.2832 - flow_loss: 19.21 - ETA: 30s - loss: 40086.2784 - spatial_transformer_2_loss: 40086.0863 - flow_loss: 19.20 - ETA: 29s - loss: 39631.0573 - spatial_transformer_2_loss: 39630.8639 - flow_loss: 19.32 - ETA: 27s - loss: 39378.4859 - spatial_transformer_2_loss: 39378.2912 - flow_loss: 19.45 - ETA: 25s - loss: 39192.6791 - spatial_transformer_2_loss: 39192.4838 - flow_loss: 19.50 - ETA: 24s - loss: 38197.7083 - spatial_transformer_2_loss: 38197.5126 - flow_loss: 19.54 - ETA: 22s - loss: 37976.0403 - spatial_transformer_2_loss: 37975.8444 - flow_loss: 19.55 - ETA: 21s - loss: 37771.5641 - spatial_transformer_2_loss: 37771.3678 - flow_loss: 19.60 - ETA: 19s - loss: 37521.0206 - spatial_transformer_2_loss: 37520.8237 - flow_loss: 19.66 - ETA: 17s - loss: 37407.8300 - spatial_transformer_2_loss: 37407.6327 - flow_loss: 19.70 - ETA: 16s - loss: 37166.8399 - spatial_transformer_2_loss: 37166.6419 - flow_loss: 19.77 - ETA: 14s - loss: 37252.5341 - spatial_transformer_2_loss: 37252.3353 - flow_loss: 19.86 - ETA: 12s - loss: 37158.7696 - spatial_transformer_2_loss: 37158.5699 - flow_loss: 19.96 - ETA: 11s - loss: 37235.4794 - spatial_transformer_2_loss: 37235.2791 - flow_loss: 20.01 - ETA: 9s - loss: 37181.6026 - spatial_transformer_2_loss: 37181.4016 - flow_loss: 20.0931 - ETA: 8s - loss: 36645.7279 - spatial_transformer_2_loss: 36645.5261 - flow_loss: 20.173 - ETA: 6s - loss: 36192.7366 - spatial_transformer_2_loss: 36192.5337 - flow_loss: 20.283 - ETA: 4s - loss: 36106.1828 - spatial_transformer_2_loss: 36105.9786 - flow_loss: 20.409 - ETA: 3s - loss: 35921.1760 - spatial_transformer_2_loss: 35920.9707 - flow_loss: 20.518 - ETA: 1s - loss: 35639.3147 - spatial_transformer_2_loss: 35639.1088 - flow_loss: 20.574 - 48s 2s/step - loss: 35234.6059 - spatial_transformer_2_loss: 35234.3994 - flow_loss: 20.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "30/30 [==============================] - ETA: 46s - loss: 36217.3125 - spatial_transformer_2_loss: 36217.0859 - flow_loss: 22.67 - ETA: 44s - loss: 35092.0410 - spatial_transformer_2_loss: 35091.8105 - flow_loss: 23.09 - ETA: 43s - loss: 34830.0703 - spatial_transformer_2_loss: 34829.8333 - flow_loss: 23.72 - ETA: 41s - loss: 35144.1191 - spatial_transformer_2_loss: 35143.8799 - flow_loss: 23.92 - ETA: 40s - loss: 32847.8668 - spatial_transformer_2_loss: 32847.6285 - flow_loss: 23.81 - ETA: 38s - loss: 33061.0459 - spatial_transformer_2_loss: 33060.8102 - flow_loss: 23.57 - ETA: 36s - loss: 32919.9422 - spatial_transformer_2_loss: 32919.7081 - flow_loss: 23.40 - ETA: 35s - loss: 31632.9119 - spatial_transformer_2_loss: 31632.6782 - flow_loss: 23.36 - ETA: 33s - loss: 31728.3021 - spatial_transformer_2_loss: 31728.0688 - flow_loss: 23.34 - ETA: 32s - loss: 30847.8857 - spatial_transformer_2_loss: 30847.6523 - flow_loss: 23.35 - ETA: 30s - loss: 31042.5534 - spatial_transformer_2_loss: 31042.3192 - flow_loss: 23.42 - ETA: 28s - loss: 31999.8110 - spatial_transformer_2_loss: 31999.5771 - flow_loss: 23.39 - ETA: 27s - loss: 32266.7961 - spatial_transformer_2_loss: 32266.5616 - flow_loss: 23.44 - ETA: 25s - loss: 32636.0632 - spatial_transformer_2_loss: 32635.8287 - flow_loss: 23.46 - ETA: 24s - loss: 32467.8249 - spatial_transformer_2_loss: 32467.5913 - flow_loss: 23.37 - ETA: 22s - loss: 31850.1156 - spatial_transformer_2_loss: 31849.8816 - flow_loss: 23.41 - ETA: 20s - loss: 31528.8755 - spatial_transformer_2_loss: 31528.6407 - flow_loss: 23.49 - ETA: 19s - loss: 31245.9593 - spatial_transformer_2_loss: 31245.7247 - flow_loss: 23.47 - ETA: 17s - loss: 31290.6185 - spatial_transformer_2_loss: 31290.3832 - flow_loss: 23.54 - ETA: 16s - loss: 31411.5360 - spatial_transformer_2_loss: 31411.3010 - flow_loss: 23.52 - ETA: 14s - loss: 31849.4190 - spatial_transformer_2_loss: 31849.1847 - flow_loss: 23.43 - ETA: 12s - loss: 31890.0733 - spatial_transformer_2_loss: 31889.8394 - flow_loss: 23.39 - ETA: 11s - loss: 31974.3354 - spatial_transformer_2_loss: 31974.1016 - flow_loss: 23.38 - ETA: 9s - loss: 31940.4085 - spatial_transformer_2_loss: 31940.1748 - flow_loss: 23.3833 - ETA: 8s - loss: 32024.1811 - spatial_transformer_2_loss: 32023.9472 - flow_loss: 23.396 - ETA: 6s - loss: 31970.6699 - spatial_transformer_2_loss: 31970.4360 - flow_loss: 23.396 - ETA: 4s - loss: 32061.2707 - spatial_transformer_2_loss: 32061.0372 - flow_loss: 23.348 - ETA: 3s - loss: 32280.0944 - spatial_transformer_2_loss: 32279.8615 - flow_loss: 23.289 - ETA: 1s - loss: 32487.5727 - spatial_transformer_2_loss: 32487.3401 - flow_loss: 23.257 - 48s 2s/step - loss: 32299.7637 - spatial_transformer_2_loss: 32299.5316 - flow_loss: 23.2039\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - ETA: 47s - loss: 30555.4102 - spatial_transformer_2_loss: 30555.1641 - flow_loss: 24.64 - ETA: 45s - loss: 33120.0898 - spatial_transformer_2_loss: 33119.8438 - flow_loss: 24.59 - ETA: 43s - loss: 32923.6595 - spatial_transformer_2_loss: 32923.4160 - flow_loss: 24.36 - ETA: 41s - loss: 32363.1562 - spatial_transformer_2_loss: 32362.9150 - flow_loss: 24.11 - ETA: 40s - loss: 30497.9113 - spatial_transformer_2_loss: 30497.6707 - flow_loss: 24.06 - ETA: 38s - loss: 29291.0371 - spatial_transformer_2_loss: 29290.7969 - flow_loss: 24.01 - ETA: 37s - loss: 29312.7489 - spatial_transformer_2_loss: 29312.5084 - flow_loss: 24.05 - ETA: 35s - loss: 29709.3013 - spatial_transformer_2_loss: 29709.0596 - flow_loss: 24.15 - ETA: 34s - loss: 28937.3602 - spatial_transformer_2_loss: 28937.1178 - flow_loss: 24.22 - ETA: 32s - loss: 29503.2816 - spatial_transformer_2_loss: 29503.0389 - flow_loss: 24.27 - ETA: 30s - loss: 28856.1515 - spatial_transformer_2_loss: 28855.9082 - flow_loss: 24.31 - ETA: 29s - loss: 29096.1484 - spatial_transformer_2_loss: 29095.9051 - flow_loss: 24.31 - ETA: 27s - loss: 29514.7007 - spatial_transformer_2_loss: 29514.4572 - flow_loss: 24.35 - ETA: 26s - loss: 29579.4088 - spatial_transformer_2_loss: 29579.1645 - flow_loss: 24.43 - ETA: 24s - loss: 29732.6215 - spatial_transformer_2_loss: 29732.3764 - flow_loss: 24.50 - ETA: 22s - loss: 29915.7062 - spatial_transformer_2_loss: 29915.4606 - flow_loss: 24.56 - ETA: 21s - loss: 29989.0771 - spatial_transformer_2_loss: 29988.8313 - flow_loss: 24.57 - ETA: 19s - loss: 29582.1322 - spatial_transformer_2_loss: 29581.8866 - flow_loss: 24.55 - ETA: 17s - loss: 29751.3049 - spatial_transformer_2_loss: 29751.0597 - flow_loss: 24.52 - ETA: 16s - loss: 29855.2698 - spatial_transformer_2_loss: 29855.0248 - flow_loss: 24.50 - ETA: 14s - loss: 30308.2735 - spatial_transformer_2_loss: 30308.0286 - flow_loss: 24.49 - ETA: 12s - loss: 29950.7722 - spatial_transformer_2_loss: 29950.5273 - flow_loss: 24.50 - ETA: 11s - loss: 30097.4314 - spatial_transformer_2_loss: 30097.1866 - flow_loss: 24.48 - ETA: 9s - loss: 29989.8213 - spatial_transformer_2_loss: 29989.5767 - flow_loss: 24.4557 - ETA: 8s - loss: 30101.8920 - spatial_transformer_2_loss: 30101.6479 - flow_loss: 24.408 - ETA: 6s - loss: 29845.4554 - spatial_transformer_2_loss: 29845.2115 - flow_loss: 24.379 - ETA: 4s - loss: 29637.4730 - spatial_transformer_2_loss: 29637.2292 - flow_loss: 24.374 - ETA: 3s - loss: 29416.9987 - spatial_transformer_2_loss: 29416.7545 - flow_loss: 24.421 - ETA: 1s - loss: 29470.1062 - spatial_transformer_2_loss: 29469.8613 - flow_loss: 24.485 - 49s 2s/step - loss: 29642.5117 - spatial_transformer_2_loss: 29642.2662 - flow_loss: 24.5467\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "with K.tf.device('/gpu:0'):\n",
    "    model = Network_Building.new_model(image_size=vol_size, layers=layers, batch_normalization=batch_normalization)\n",
    "    gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    K.set_session(sess)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate),\n",
    "                     loss=[data_loss, losses.Grad('l2').loss],\n",
    "                     loss_weights=[1.0, regularization_parameter])\n",
    "\n",
    "    # fit\n",
    "    model.fit_generator(data_gen,\n",
    "                           initial_epoch=0,\n",
    "                           epochs=number_of_epochs,\n",
    "                           callbacks=callbacks,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around! Add more layers, convolutions, see if you can reduce your loss the most, change the bottom two files, make sure to rename your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {'Layer_0':{'Encoding':[16],'Decoding':[16,16]},\n",
    "          'Layer_1':{'Encoding':[32],'Decoding':[32,32]},\n",
    "          'Layer_2':{'Encoding':[32],'Decoding':[32]},\n",
    "          'Layer_3':{'Encoding':[32],'Decoding':[32]},\n",
    "          'Base':{'Encoding':[32]}}\n",
    "model_desc = 'Deep_net' # Name of your model\n",
    "# The numbers inside are the number of filter banks, you can have mulitple filter banks per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\\Morfeus\\AAPM_SummerSchool\\voxelmorph\\Tensorboard_models\\Deep_net\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model_class = Network_Building.new_model(image_size=vol_size,layers=layers, visualize=True)\n",
    "model = model_class.model\n",
    "tensorboard_output = os.path.join('..','Tensorboard_models',model_desc)\n",
    "if not os.path.exists(tensorboard_output):\n",
    "    os.makedirs(tensorboard_output)\n",
    "print(os.path.abspath(tensorboard_output))\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_output, batch_size=2, write_graph=True, write_grads=False,\n",
    "                          write_images=True, update_freq='epoch', histogram_freq=0)\n",
    "tensorboard.set_model(model)\n",
    "tensorboard._write_logs({},0)\n",
    "model_output = os.path.join(model_dir, model_desc, 'Model_saves')\n",
    "save_file_name = os.path.join(model_output,'weights-improvement-{epoch:02d}.hdf5')\n",
    "checkpoint = ModelCheckpoint(save_file_name, save_weights_only=False, period=1)\n",
    "callbacks = [checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
