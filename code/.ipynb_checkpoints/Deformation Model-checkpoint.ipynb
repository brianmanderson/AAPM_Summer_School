{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure runtime is set to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow-gpu)\n",
      "Requirement already satisfied: html5lib==0.9999999 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu)\n",
      "Requirement already satisfied: bleach==1.5.0 in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from protobuf>=3.4.0->tensorflow-gpu)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "\n",
    "class download_data_from_folder(object):\n",
    "    def __init__(self,path):\n",
    "        path_id = path[path.find('id=')+3:]\n",
    "        self.file_list = self.get_files_in_location(path_id)\n",
    "        self.unwrap_data(self.file_list)\n",
    "    def get_files_in_location(self,folder_id):\n",
    "        file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n",
    "        return file_list\n",
    "    def unwrap_data(self,file_list,directory='.'):\n",
    "        for i, file in enumerate(file_list):\n",
    "            print(str((i + 1) / len(file_list) * 100) + '% done copying')\n",
    "            if file['mimeType'].find('folder') != -1:\n",
    "                if not os.path.exists(os.path.join(directory, file['title'])):\n",
    "                    os.makedirs(os.path.join(directory, file['title']))\n",
    "                print('Copying folder ' + os.path.join(directory, file['title']))\n",
    "                self.unwrap_data(self.get_files_in_location(file['id']), os.path.join(directory, file['title']))\n",
    "            else:\n",
    "                if not os.path.exists(os.path.join(directory, file['title'])):\n",
    "                    downloaded = drive.CreateFile({'id': file['id']})\n",
    "                    downloaded.GetContentFile(os.path.join(directory, file['title']))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'https://drive.google.com/open?id=1oFxTLOPF46IQljQYH0UFPg59nIvwInrY'\n",
    "download_data_from_folder(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\bmanderson\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\dicom\\__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os, glob\n",
    "sys.path.append(os.path.join('..','ext','neuron'))\n",
    "import numpy as np\n",
    "from Zip_data import Unzip_class\n",
    "from Utils import normalize, visualize_model, create_model, train, load_atlas, data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "data_path = os.path.abspath('//content//gdrive//My Drive//AAPM Summer School//code')\n",
    "os.chdir(data_path)\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model location and registered data\n",
    "Also unzip data if we haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','Reg_Data')\n",
    "if not os.path.exists(data_dir):\n",
    "    print('Unzipping data')\n",
    "    Unzip_class(os.path.join('..','Reg_Data'),r'..')\n",
    "    print('Finished unzipping')\n",
    "model_dir = os.path.join('..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the atlas file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_file= os.path.join('..','reg_data','Atlas_Data.npy')\n",
    "atlas_vol = load_atlas(atlas_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your model\n",
    "\n",
    "This is the part that you have the most unique control over, what exactly will your model look like?\n",
    "\n",
    "One good way of visualizing the model is to create it and look at the graphical architecture with tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start off with something simple, a UNet with one concatentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {'Layer_0':{'Encoding':[16,32],'Decoding':[32,16,8]},\n",
    "          'Base':{'Encoding':[64]}}\n",
    "model_desc = 'Shallow_net' # Name of your model\n",
    "# The numbers inside are the number of filter banks, you can have mulitple filter banks per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be imagined as a U net, the numbers within [] are the number of filters in the convolution blocks, the network will first perform convolutions downthe encoding side to the base, and then concatenate from the previous encoding layer before performing decoding convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not look like much, but lets see what it looks like graphically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created at: K:\\Morfeus\\AAPM_SummerSchool\\bma_voxel_morph\\Tensorboard_models\\Shallow_net\n"
     ]
    }
   ],
   "source": [
    "visualize_model(layers, atlas_vol.shape[1:-1], model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = os.path.join('..','Tensorboard_models')\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 116 registrations available\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator(atlas_vol,data_dir)\n",
    "print('We have ' + str(len(train_generator)) + ' registrations available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters\n",
    "These are variables which you will manipulate in order to create the best model possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # Rate at which our gradients will change during each back propogation, typically in range of 1e-2 to 1e-5\n",
    "number_of_epochs = 10 # The number of epochs to be trained, one epoch means that you have seen the entirety of your dataset\n",
    "                      # However, since we defined steps per epoch this might not apply\n",
    "regularization_parameter = 0.01 # Lambda in regularization equation\n",
    "steps_per_epoch = 30\n",
    "loss_function = 'mse'\n",
    "batch_normalization = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = create_model(layers, atlas_vol.shape[1:-1], model_desc, batch_norm=batch_normalization, data_generator=train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/30 [=============>................] - ETA: 10:15 - loss: 0.0334 - spatial_transformer_1_loss: 0.0334 - flow_loss: 1.1482e-0 - ETA: 5:21 - loss: 0.0302 - spatial_transformer_1_loss: 0.0302 - flow_loss: 8.1864e-0 - ETA: 3:41 - loss: 0.0268 - spatial_transformer_1_loss: 0.0268 - flow_loss: 2.6281e- - ETA: 2:51 - loss: 0.0249 - spatial_transformer_1_loss: 0.0249 - flow_loss: 5.6768e- - ETA: 2:20 - loss: 0.0236 - spatial_transformer_1_loss: 0.0236 - flow_loss: 0.0010   - ETA: 1:59 - loss: 0.0229 - spatial_transformer_1_loss: 0.0229 - flow_loss: 0.00 - ETA: 1:43 - loss: 0.0215 - spatial_transformer_1_loss: 0.0215 - flow_loss: 0.00 - ETA: 1:31 - loss: 0.0211 - spatial_transformer_1_loss: 0.0210 - flow_loss: 0.00 - ETA: 1:21 - loss: 0.0209 - spatial_transformer_1_loss: 0.0208 - flow_loss: 0.00 - ETA: 1:13 - loss: 0.0223 - spatial_transformer_1_loss: 0.0222 - flow_loss: 0.00 - ETA: 1:06 - loss: 0.0222 - spatial_transformer_1_loss: 0.0221 - flow_loss: 0.00 - ETA: 1:00 - loss: 0.0217 - spatial_transformer_1_loss: 0.0216 - flow_loss: 0.00 - ETA: 54s - loss: 0.0215 - spatial_transformer_1_loss: 0.0214 - flow_loss: 0.0098 - ETA: 49s - loss: 0.0212 - spatial_transformer_1_loss: 0.0211 - flow_loss: 0.0113"
     ]
    }
   ],
   "source": [
    "train(model, train_generator, callbacks, learning_rate, number_of_epochs, \n",
    "      regularization_parameter, steps_per_epoch,loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor progress and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = os.path.join('..','Tensorboard_models')\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around! Add more layers, convolutions, see if you can reduce your loss the most, change the bottom two files, make sure to rename your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {'Layer_0':{'Encoding':[16],'Decoding':[16,16]},\n",
    "          'Layer_1':{'Encoding':[32],'Decoding':[32,32]},\n",
    "          'Layer_2':{'Encoding':[32],'Decoding':[32]},\n",
    "          'Layer_3':{'Encoding':[32],'Decoding':[32]},\n",
    "          'Base':{'Encoding':[32]}}\n",
    "model_desc = 'Deep_net' # Name of your model\n",
    "# The numbers inside are the number of filter banks, you can have mulitple filter banks per layer\n",
    "visualize_model(layers, atlas_vol.shape[1:-1], model_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View your model by scrolling up to look at the tensorboard module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\\Morfeus\\AAPM_SummerSchool\\bma_voxel_morph\\Tensorboard_models\\Deep_net\n"
     ]
    }
   ],
   "source": [
    "model, callbacks = create_model(layers, atlas_vol.shape[1:-1], model_desc, batch_norm=batch_normalization, data_generator=train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_generator, callbacks, learning_rate, number_of_epochs, \n",
    "      regularization_parameter, steps_per_epoch,loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
